{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Load modules and define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code for training VAE on Tabula Muris heart data\n",
    "\"\"\"\n",
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import distributions as ds\n",
    "\n",
    "\n",
    "from nets import *\n",
    "from lib import *\n",
    "\n",
    "\n",
    "class Options(object):\n",
    "    def __init__(self, num_cells_train, gex_size):\n",
    "        self.num_cells_train =  num_cells_train  # number of cells\n",
    "        self.gex_size = gex_size                 # number of genes\n",
    "        self.epsilon_use = 1e-16                 # small constant value\n",
    "        self.n_train_epochs = 100                 # number of epochs for training\n",
    "        self.batch_size = 32                     # batch size of the GAN-based methods\n",
    "        self.vae_batch_size = 128                # batch size of the VAE-based methods\n",
    "        self.code_size = 10                      # number of codes\n",
    "        self.noise_size = 118                    # number of noise variables\n",
    "        self.inflate_to_size1 = 256              # number of neurons\n",
    "        self.inflate_to_size2 = 512              # number of neurons\n",
    "        self.inflate_to_size3 = 1024             # number of neurons\n",
    "        self.TotalCorrelation_lamb = 0.0         # hyperparameter for the total correlation penalty in beta-TCVAE\n",
    "        self.InfoGAN_fix_std = True              # fixing the standard deviation or not for the Q network of InfoGAN\n",
    "        self.dropout_rate = 0.2                  # dropout hyperparameter\n",
    "        self.disc_internal_size1 = 1024          # number of neurons\n",
    "        self.disc_internal_size2 = 512           # number of neurons\n",
    "        self.disc_internal_size3 = 10            # number of neurons\n",
    "        self.num_cells_generate = 3000           # number of sampled cells\n",
    "        self.GradientPenaly_lambda = 10.0        # hyperparameter for the gradient penalty of Wasserstein GANs\n",
    "        self.latentSample_size = 1               # number of samples of the encoder of VAEs\n",
    "        self.MutualInformation_lamb = 10.0       # hyperparameter for the mutual information penalty in InfoGAN\n",
    "        self.Diters = 5                          # number of training discriminator network per training of generator network of Wasserstein GANs\n",
    "        self.model_path = \"./examples/models_vae/\"        # path saving the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Load data and define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix = np.load('./data/TabulaMurisHeart_Processed.npy')\n",
    "data_meta = pd.read_csv(\"./data/TabulaMurisHeart_MetaInformation.csv\")\n",
    "opt = Options(data_matrix.shape[0], data_matrix.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Define network tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hengshi/MichiGAN/nets.py:292: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/hengshi/MichiGAN/nets.py:16: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54e1353f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54e1353f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54e1353f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54e1353f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/hengshi/MichiGAN/nets.py:17: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x2b54fc5e1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x2b54fc5e1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x2b54fc5e1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x2b54fc5e1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/hengshi/MichiGAN/nets.py:19: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x2b54fc5e1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x2b54fc5e1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x2b54fc5e1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x2b54fc5e1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc5e1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc5e1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc5e1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc5e1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x2b54fc5e1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x2b54fc5e1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x2b54fc5e1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x2b54fc5e1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x2b54fc5e1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x2b54fc5e1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x2b54fc5e1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x2b54fc5e1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/hengshi/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc5e1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc5e1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc5e1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc5e1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc5e1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc5e1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc5e1240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc5e1240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/hengshi/MichiGAN/lib.py:134: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/hengshi/MichiGAN/lib.py:138: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hengshi/MichiGAN/lib.py:30: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fca730f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fca730f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fca730f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fca730f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x2b54fc7b6898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x2b54fc7b6898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x2b54fc7b6898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x2b54fc7b6898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x2b54fc7b6898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x2b54fc7b6898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x2b54fc7b6898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x2b54fc7b6898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc7b6898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc7b6898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc7b6898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc7b6898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x2b54fc6a60b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x2b54fc6a60b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x2b54fc6a60b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x2b54fc6a60b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x2b54fc6a60b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x2b54fc6a60b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x2b54fc6a60b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x2b54fc6a60b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc6a60b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc6a60b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc6a60b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x2b54fc6a60b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/hengshi/MichiGAN/nets.py:76: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /home/hengshi/.local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "z_v = tf.placeholder(tf.float32, shape = (None, opt.code_size))\n",
    "X_v = tf.placeholder(tf.float32, shape = (None, opt.gex_size))\n",
    "\n",
    "## encoder\n",
    "z_gen_mean_v, z_gen_std_v = vaes_encoder(X_v, opt)\n",
    "\n",
    "### reparameterization of latent space\n",
    "batch_size = tf.shape(z_gen_mean_v)[0]\n",
    "eps = tf.random_normal(shape=[batch_size, opt.code_size])\n",
    "z_gen_data_v = z_gen_mean_v + z_gen_std_v * eps\n",
    "\n",
    "### latent entropies in a minibatch\n",
    "margin_entropy_mss, joint_entropy_mss = estimate_minibatch_mss_entropy(z_gen_mean_v, z_gen_std_v, z_gen_data_v, opt)\n",
    "### total correlation in a minibatch\n",
    "TotalCorre_mss = tf.reduce_sum(margin_entropy_mss) - tf.reduce_sum(joint_entropy_mss)\n",
    "\n",
    "## decoder\n",
    "z_gen_decoder = vaes_decoder(z_gen_data_v, opt)\n",
    "\n",
    "### generated data\n",
    "X_gen_data = z_gen_decoder.sample(opt.latentSample_size)\n",
    "X_gen_data = tf.reshape(X_gen_data , tf.shape(X_gen_data)[1:])\n",
    "\n",
    "## loss elements\n",
    "### reconstruction error\n",
    "z_gen_de = z_gen_decoder.log_prob(X_v)\n",
    "z_gen_de_value = tf.reduce_sum(z_gen_de, [1])\n",
    "rec_x_loss = - tf.reduce_mean(z_gen_de_value)\n",
    "\n",
    "### latent prior and posterior probabilities\n",
    "stg_prior = tf_standardGaussian_prior(tf.shape(X_v)[0], opt.code_size)\n",
    "latent_prior = stg_prior.log_prob(z_gen_data_v)\n",
    "latent_posterior = c_mutual_mu_var_entropy(z_gen_mean_v, z_gen_std_v, z_gen_data_v, opt)\n",
    "\n",
    "### latent joint prior and posterior probabilities\n",
    "latent_prior_joint = tf.reduce_sum(latent_prior, [1])\n",
    "latent_posterior_joint = tf.reduce_sum(latent_posterior, [1])\n",
    "\n",
    "### KL divergence\n",
    "kl_latent = - tf.reduce_mean(latent_prior_joint) + tf.reduce_mean(latent_posterior_joint)\n",
    "\n",
    "### VAE/beta-TCVAE loss function\n",
    "obj_vae = rec_x_loss  + kl_latent + opt.TotalCorrelation_lamb * TotalCorre_mss\n",
    "\n",
    "## time step\n",
    "time_step = tf.placeholder(tf.int32)\n",
    "\n",
    "## training tensors \n",
    "tf_all_vars = tf.trainable_variables()\n",
    "encodervar  = [var for var in tf_all_vars if var.name.startswith(\"EncoderX2Z\")]\n",
    "decodervar  = [var for var in tf_all_vars if var.name.startswith(\"DecoderZ2X\")]\n",
    "\n",
    "optimizer_vae = tf.train.AdamOptimizer(1e-4)\n",
    "opt_vae = optimizer_vae.minimize(obj_vae, var_list = encodervar + decodervar)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "global_step = tf.Variable(0, name = 'global_step', trainable = False, dtype = tf.int32)\n",
    "\n",
    "sess = tf.InteractiveSession()\t\n",
    "init = tf.global_variables_initializer().run()\n",
    "assign_step_zero = tf.assign(global_step, 0)\n",
    "init_step = sess.run(assign_step_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Training the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0; iteration: 32; VAE loss:4488.45361328125; Total Correlation:0.015956878662109375\n",
      "epoch: 1; iteration: 64; VAE loss:4452.82666015625; Total Correlation:0.42754554748535156\n",
      "epoch: 2; iteration: 96; VAE loss:4510.43505859375; Total Correlation:0.8348712921142578\n",
      "epoch: 3; iteration: 128; VAE loss:4454.6806640625; Total Correlation:1.6777191162109375\n",
      "epoch: 4; iteration: 160; VAE loss:4446.32666015625; Total Correlation:1.3053874969482422\n",
      "epoch: 5; iteration: 192; VAE loss:4354.650390625; Total Correlation:1.7191247940063477\n",
      "epoch: 6; iteration: 224; VAE loss:4486.72802734375; Total Correlation:2.392306327819824\n",
      "epoch: 7; iteration: 256; VAE loss:4447.048828125; Total Correlation:2.5851306915283203\n",
      "epoch: 8; iteration: 288; VAE loss:4417.60546875; Total Correlation:2.458327293395996\n",
      "epoch: 9; iteration: 320; VAE loss:4419.33154296875; Total Correlation:2.053469657897949\n",
      "epoch: 10; iteration: 352; VAE loss:4429.89794921875; Total Correlation:2.420877456665039\n",
      "epoch: 11; iteration: 384; VAE loss:4422.50146484375; Total Correlation:2.1379871368408203\n",
      "epoch: 12; iteration: 416; VAE loss:4389.13134765625; Total Correlation:3.226011276245117\n",
      "epoch: 13; iteration: 448; VAE loss:4452.33447265625; Total Correlation:2.044595718383789\n",
      "epoch: 14; iteration: 480; VAE loss:4373.36572265625; Total Correlation:2.657801628112793\n",
      "epoch: 15; iteration: 512; VAE loss:4386.529296875; Total Correlation:2.3150320053100586\n",
      "epoch: 16; iteration: 544; VAE loss:4395.75830078125; Total Correlation:2.457016944885254\n",
      "epoch: 17; iteration: 576; VAE loss:4410.57568359375; Total Correlation:2.373077392578125\n",
      "epoch: 18; iteration: 608; VAE loss:4456.70458984375; Total Correlation:3.5280895233154297\n",
      "epoch: 19; iteration: 640; VAE loss:4372.59375; Total Correlation:2.6744327545166016\n",
      "epoch: 20; iteration: 672; VAE loss:4418.791015625; Total Correlation:2.4489479064941406\n",
      "epoch: 21; iteration: 704; VAE loss:4437.416015625; Total Correlation:2.521575927734375\n",
      "epoch: 22; iteration: 736; VAE loss:4400.04931640625; Total Correlation:2.8656978607177734\n",
      "epoch: 23; iteration: 768; VAE loss:4394.57421875; Total Correlation:2.614712715148926\n",
      "epoch: 24; iteration: 800; VAE loss:4360.00390625; Total Correlation:3.4397335052490234\n",
      "epoch: 25; iteration: 832; VAE loss:4349.6748046875; Total Correlation:2.1469650268554688\n",
      "epoch: 26; iteration: 864; VAE loss:4437.5771484375; Total Correlation:3.189115524291992\n",
      "epoch: 27; iteration: 896; VAE loss:4403.53564453125; Total Correlation:3.029054641723633\n",
      "epoch: 28; iteration: 928; VAE loss:4464.00927734375; Total Correlation:4.426290512084961\n",
      "epoch: 29; iteration: 960; VAE loss:4365.73486328125; Total Correlation:3.3358154296875\n",
      "epoch: 30; iteration: 992; VAE loss:4364.04150390625; Total Correlation:3.0203332901000977\n",
      "epoch: 31; iteration: 1024; VAE loss:4402.578125; Total Correlation:3.2749691009521484\n",
      "epoch: 32; iteration: 1056; VAE loss:4408.32861328125; Total Correlation:2.6667232513427734\n",
      "epoch: 33; iteration: 1088; VAE loss:4373.32763671875; Total Correlation:2.2068662643432617\n",
      "epoch: 34; iteration: 1120; VAE loss:4462.67236328125; Total Correlation:3.588315963745117\n",
      "epoch: 35; iteration: 1152; VAE loss:4377.7265625; Total Correlation:3.2163314819335938\n",
      "epoch: 36; iteration: 1184; VAE loss:4419.4208984375; Total Correlation:3.438900947570801\n",
      "epoch: 37; iteration: 1216; VAE loss:4415.08154296875; Total Correlation:3.0598602294921875\n",
      "epoch: 38; iteration: 1248; VAE loss:4384.20556640625; Total Correlation:3.5614986419677734\n",
      "epoch: 39; iteration: 1280; VAE loss:4431.60400390625; Total Correlation:3.623981475830078\n",
      "epoch: 40; iteration: 1312; VAE loss:4412.11767578125; Total Correlation:3.536235809326172\n",
      "epoch: 41; iteration: 1344; VAE loss:4417.67724609375; Total Correlation:3.9276514053344727\n",
      "epoch: 42; iteration: 1376; VAE loss:4377.7666015625; Total Correlation:3.1481552124023438\n",
      "epoch: 43; iteration: 1408; VAE loss:4363.72607421875; Total Correlation:3.243793487548828\n",
      "epoch: 44; iteration: 1440; VAE loss:4359.712890625; Total Correlation:2.570636749267578\n",
      "epoch: 45; iteration: 1472; VAE loss:4387.00048828125; Total Correlation:2.8308048248291016\n",
      "epoch: 46; iteration: 1504; VAE loss:4451.80712890625; Total Correlation:4.110552787780762\n",
      "epoch: 47; iteration: 1536; VAE loss:4396.0078125; Total Correlation:3.555943489074707\n",
      "epoch: 48; iteration: 1568; VAE loss:4371.857421875; Total Correlation:3.145000457763672\n",
      "epoch: 49; iteration: 1600; VAE loss:4395.74853515625; Total Correlation:3.692190170288086\n",
      "epoch: 50; iteration: 1632; VAE loss:4429.66748046875; Total Correlation:3.9726219177246094\n",
      "epoch: 51; iteration: 1664; VAE loss:4335.66357421875; Total Correlation:3.956531524658203\n",
      "epoch: 52; iteration: 1696; VAE loss:4465.0048828125; Total Correlation:4.071649551391602\n",
      "epoch: 53; iteration: 1728; VAE loss:4402.74072265625; Total Correlation:3.6752099990844727\n",
      "epoch: 54; iteration: 1760; VAE loss:4447.76806640625; Total Correlation:4.359065055847168\n",
      "epoch: 55; iteration: 1792; VAE loss:4361.005859375; Total Correlation:2.8729019165039062\n",
      "epoch: 56; iteration: 1824; VAE loss:4345.037109375; Total Correlation:2.8726768493652344\n",
      "epoch: 57; iteration: 1856; VAE loss:4435.19482421875; Total Correlation:4.121546745300293\n",
      "epoch: 58; iteration: 1888; VAE loss:4421.95654296875; Total Correlation:3.8280982971191406\n",
      "epoch: 59; iteration: 1920; VAE loss:4406.34033203125; Total Correlation:3.5756378173828125\n",
      "epoch: 60; iteration: 1952; VAE loss:4439.609375; Total Correlation:4.860749244689941\n",
      "epoch: 61; iteration: 1984; VAE loss:4427.5478515625; Total Correlation:3.6245269775390625\n",
      "epoch: 62; iteration: 2016; VAE loss:4360.10107421875; Total Correlation:3.486893653869629\n",
      "epoch: 63; iteration: 2048; VAE loss:4367.01318359375; Total Correlation:3.3462162017822266\n",
      "epoch: 64; iteration: 2080; VAE loss:4420.57470703125; Total Correlation:3.5495376586914062\n",
      "epoch: 65; iteration: 2112; VAE loss:4381.72412109375; Total Correlation:4.251965522766113\n",
      "epoch: 66; iteration: 2144; VAE loss:4411.654296875; Total Correlation:3.911916732788086\n",
      "epoch: 67; iteration: 2176; VAE loss:4380.64453125; Total Correlation:2.8961896896362305\n",
      "epoch: 68; iteration: 2208; VAE loss:4395.498046875; Total Correlation:3.440068244934082\n",
      "epoch: 69; iteration: 2240; VAE loss:4415.40966796875; Total Correlation:2.9104232788085938\n",
      "epoch: 70; iteration: 2272; VAE loss:4408.84912109375; Total Correlation:4.250789642333984\n",
      "epoch: 71; iteration: 2304; VAE loss:4349.45556640625; Total Correlation:3.1935997009277344\n",
      "epoch: 72; iteration: 2336; VAE loss:4403.21923828125; Total Correlation:4.586207389831543\n",
      "epoch: 73; iteration: 2368; VAE loss:4416.96142578125; Total Correlation:4.275154113769531\n",
      "epoch: 74; iteration: 2400; VAE loss:4355.15185546875; Total Correlation:3.659168243408203\n",
      "epoch: 75; iteration: 2432; VAE loss:4408.68408203125; Total Correlation:3.762375831604004\n",
      "epoch: 76; iteration: 2464; VAE loss:4392.34130859375; Total Correlation:4.220189094543457\n",
      "epoch: 77; iteration: 2496; VAE loss:4373.4248046875; Total Correlation:3.2767457962036133\n",
      "epoch: 78; iteration: 2528; VAE loss:4357.9619140625; Total Correlation:4.478921890258789\n",
      "epoch: 79; iteration: 2560; VAE loss:4349.31396484375; Total Correlation:3.4620418548583984\n",
      "epoch: 80; iteration: 2592; VAE loss:4371.47412109375; Total Correlation:4.372772216796875\n",
      "epoch: 81; iteration: 2624; VAE loss:4407.68310546875; Total Correlation:4.197912216186523\n",
      "epoch: 82; iteration: 2656; VAE loss:4421.21044921875; Total Correlation:4.7066450119018555\n",
      "epoch: 83; iteration: 2688; VAE loss:4368.93017578125; Total Correlation:3.7771310806274414\n",
      "epoch: 84; iteration: 2720; VAE loss:4368.314453125; Total Correlation:4.064357757568359\n",
      "epoch: 85; iteration: 2752; VAE loss:4423.18359375; Total Correlation:3.881251335144043\n",
      "epoch: 86; iteration: 2784; VAE loss:4372.8212890625; Total Correlation:3.6978464126586914\n",
      "epoch: 87; iteration: 2816; VAE loss:4380.54052734375; Total Correlation:3.4228153228759766\n",
      "epoch: 88; iteration: 2848; VAE loss:4395.03173828125; Total Correlation:3.86501407623291\n",
      "epoch: 89; iteration: 2880; VAE loss:4385.08251953125; Total Correlation:3.6984996795654297\n",
      "epoch: 90; iteration: 2912; VAE loss:4378.33740234375; Total Correlation:4.789571762084961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 91; iteration: 2944; VAE loss:4350.9013671875; Total Correlation:3.133279800415039\n",
      "epoch: 92; iteration: 2976; VAE loss:4391.2119140625; Total Correlation:4.103702545166016\n",
      "epoch: 93; iteration: 3008; VAE loss:4394.4736328125; Total Correlation:4.899969100952148\n",
      "epoch: 94; iteration: 3040; VAE loss:4373.50341796875; Total Correlation:4.018097877502441\n",
      "epoch: 95; iteration: 3072; VAE loss:4455.162109375; Total Correlation:4.76351261138916\n",
      "epoch: 96; iteration: 3104; VAE loss:4403.81396484375; Total Correlation:4.133835792541504\n",
      "epoch: 97; iteration: 3136; VAE loss:4391.93896484375; Total Correlation:4.0433244705200195\n",
      "epoch: 98; iteration: 3168; VAE loss:4355.60400390625; Total Correlation:4.262432098388672\n",
      "epoch: 99; iteration: 3200; VAE loss:4375.0166015625; Total Correlation:2.947159767150879\n"
     ]
    }
   ],
   "source": [
    "x_input = data_matrix.copy()\n",
    "index_shuffle = list(range(opt.num_cells_train))\n",
    "current_step = 0\n",
    "\n",
    "for epoch in range(opt.n_train_epochs):\n",
    "    # shuffling the data per epoch\n",
    "    np.random.shuffle(index_shuffle)\n",
    "    x_input = x_input[index_shuffle, :]\n",
    "\n",
    "    for i in range(0, opt.num_cells_train // opt.vae_batch_size):\n",
    "\n",
    "        # train VAE/beta-TCVAE in each minibatch\n",
    "        x_data = sample_X(x_input, opt.vae_batch_size)\n",
    "        z_data = noise_prior(opt.vae_batch_size, opt.code_size)\n",
    "        sess.run([opt_vae], {X_v : x_data, z_v: z_data, time_step : current_step})\n",
    "\n",
    "        current_step += 1\n",
    "\n",
    "    obj_vae_value, TC_value = sess.run([obj_vae, TotalCorre_mss], {X_v : x_data, z_v: z_data, time_step : current_step})\n",
    "\n",
    "    print('epoch: {}; iteration: {}; VAE loss:{}; Total Correlation:{}'.format(epoch, current_step, obj_vae_value, TC_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = opt.model_path + \"models_vae\"\n",
    "saving_model = saver.save(sess, model_file_path, global_step = current_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
